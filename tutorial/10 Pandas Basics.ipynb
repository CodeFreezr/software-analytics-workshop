{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction\n",
                "This notebook is a simple mini-tutorial to introduce you to basic functions of Jupyter, Python, pandas and matplotlib with the aim of analyzing software data. Therefore, the example is chosen in such a way that we come across the typical methods in a data analysis. Have fun!\n",
                "\n",
                "*This is part II: The basic of the data analysis framework pandas. For Jupyter and Python basics, got to [00_jupyter_python_basics.ipynb](00_jupyter_python_basics.ipynb).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Analysis with pandas\n",
                "OK, let's start learning pandas with a little analysis!\n",
                "\n",
                "In this notebook, we want to take a closer look at the development history of the open source project \"Linux\" based on the history of the corresponding GitHub mirror repository.\n",
                "\n",
                "A local clone of the GitHub repository https://github.com/torvalds/linux/ was created by using the command  \n",
                "\n",
                "```\n",
                "git clone https://github.com/torvalds/linux.git\n",
                "```\n",
                "\n",
                "The relevant parts of the history for this analysis were produced by using\n",
                "\n",
                "```\n",
                "git log --pretty=\"%ad,%aN\" --no-merges > git_log_linux_authors_timestamps.csv\n",
                "```\n",
                "\n",
                "This command returned the commit timestamp (`%ad`) and the author name (`%aN`) for each commit of the Git repository. The corresponding values are separated by commas. We also indicated that we do not want to receive merge commits (via `--no-merges`). The result of the output was saved in the file `git_log_linux_authors_timestamps.csv` and compressed for a optimized file size with `gzip` to the file `git_log_linux_authors_timestamps.gz`.\n",
                "\n",
                "_Note: For an optimized demo, headers and the separator has been changed manually in the provided dataset to get through this analysis more easily. The differences can be seen at https://www.feststelltaste.de/developers-habits-linux-edition/, which was done with the original dataset._"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Getting to know pandas\n",
                "Pandas is a data analysis tool written in Python (and C), which is ideally suited for the evaluation of tabular data due to the use of effective data structures and built-in statistics functions.\n",
                "\n",
                "## Basics\n",
                "\n",
                "We import the data from above with the help of Pandas. We import `pandas` with the common abbreviation `pd` using the `import... as..` syntax of Python."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can check whether the import of the module really worked by checking the documentation of the `pd` module. To do this, we append the `?` operator to the `pd` variable and execute the cell. The documentation of the module appears in the lower part of the browser window. We can read through this area and make it disappear again with the `ESC` key."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We read the compressed CSV file `git_log_linux_authors_timestamps.gz` in the directory `../datasets` with the `read_csv()` method into a DataFrame.\n",
                "\n",
                "The result of our execution is stored in the variable `git_log`. We've just loaded data into a so-called **DataFrame** (something like a programmable Excel worksheet), which in our case consists of two **Series** (= columns). \n",
                "\n",
                "We can now perform operations on the DataFrame. For example, we can use `head()` to display the first five entries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we call `info()` on the `DataFrame` to get some basic data about the read in data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can access the individual Series / columns by using the `['<column name>']` or (in most cases, i.e. as long as the column names do not overlap with the method name offered by the `DataFrame` itself) by directly using the name of the `Series`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## First Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also perform various operations on a `Series`. For example, with `value_counts()`, we can count the values contained in a `Series` and let them sort according to their frequency. The result is again a `Series`, but this time with the totaled and sorted values. We can additionally call `head(10)` on this `Series`. This gives us a quick way to display the TOP-10 values of a `Series`. We can then record the result in a variable `top10` and output it by writing the variable to the next cell row."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## First visualizations\n",
                "Next, we want to visualize or plot the result. To display the plotting result of the internally used plotting library `matplotlib` directly in the notebook, we have to execute this magic command in our notebook\n",
                "\n",
                "```\n",
                "%matplotlib inline\n",
                "```\n",
                "\n",
                "before calling the `plot()` method.\n",
                "\n",
                "By default, when `plot()` is called on a `DataFrame` or `Series`, a line chart is created."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "That doesn't make much sense here, so we use a sub-method of `plot` called `bar()` to create a bar chart."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This data can also be visualized as a pie chart. For this, we call the `pie()` method instead of `bar()`. We can also add a semicolon `;` after the `plot` command to avoid printing the text of the reference. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "However, the diagram does not look very nice here.\n",
                "\n",
                "With the optional styling parameters, we can achieve that we get a nicer graphics. We use\n",
                "* `figsize=[7,7]` as size\n",
                "* `title=\"Top 10 authors\"` as title\n",
                "* `labels=None` to avoid displaying the superfluous label on the left."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Working with dates\n",
                "Now let's look at the timestamp information. We want to find out at what time of day the developers commit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before we can enter the world of time series processing, we must first convert our column with the dates into the appropriate data type. At the moment our column `timestamp` is still a string, i.e. of textual nature. We can see this by using the helper function `type(<object>)` to display the first entry of the `timestamp` column:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Of course, Pandas also helps us to convert data types. The function `pd.to_datetime` takes as first parameter a `series` with dates and converts them. The return value is a `Series` with values of the data type `Timestamp`. The conversion works for most textual dates mostly automagically [sic!], because Pandas can handle different date formats. We also write the result back into the same column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To check if the conversion was successful, we can check the first value of our converted column `timestamp_local` by calling `type()` again."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now also access individual parts of the date values. For this, we use the `dt` (\"datetime\") object with its properties like `hour`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Together with the `value_counts()` method that I've already introduced above, we can now count values again after their occurrence. However, it is important that we also set the parameter `sort=False` to avoid sorting according to keep the order of the hours."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can display the result by means of a bar chart and thus get an overview of how many commits occured for each hour."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now additionally label the plot. To do this, we store the return object of the `bar()` function in the variable `ax`. This is an `Axes` object of the underlying plotting library `matplotlib`, through which we can customize additional properties of the plot. We set here\n",
                "\n",
                "* the title \"Commits per Hour\" via `set_title(\"<titel name>\")`\n",
                "* the label \"Hour of Day\" of the X-axis with `set_xlabel(\"<X-axis label>\")`\n",
                "* the label \"Number of Commits\" of the Y-axis with `set_ylabel<\"Y-axis label>\")`\n",
                "\n",
                "The result is a more meaningful, labeled bar chart."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also analyze the commits per weekdays. To do this, we use the `weekday` attribute of the datetime attribute `dt`. The values here are 0-based with Monday as the first day of the week. As usual, we count the values using `value_counts` and do not sort the values by size but keep the sorting by weekday."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The result in `commits_per_weekday` can be output as a bar chart using `plot.bar()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Displaying the commit history\n",
                "In the following, we want to see the progress of the number of commits over the last years by using a `DatetimeIndex` based DataFrame. To do this, we set the `timestamp` column as index using `set_index('<columnname>')`. Furthermore, we select just the `author` column. Thus we work continuously on a pure `Series` instead of a `DataFrame`. \n",
                "\n",
                "Side note: The usage of a `Series` is almost similar to a `DataFrame` with regard to the statistical functions. However, a `Series` is not beautifully formatted in a table, which is why I personally prefer using a `DataFrame`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Using the `resample(\"<time unit>\")` function of the `DataFrame`, we can now group values according to certain time units such as days (`D`), months (`M`), quarters (`Q`) or years (`A`). We use a `resample(\"D\")` for counting per day. We also specify how the individual values should be combined per time unit. For this, we select the `count()` function to count the number of commits for each day."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To show the commit history over the years, we calculate the cumulative sum of all daily entries using `cumsum()`. All values get summed up one after the other."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The result is plotted as a line diagram and the number of commits is shown over the years."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "delete"
                ]
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# What you've learned\n",
                "OK, that's it for now!\n",
                "\n",
                "You've learned some basics about Pandas and its usage with software data. This will hopefully get you started in your daily work. Other important topics that are still missing are:\n",
                "\n",
                "* Reading in complicated or semi-structured data structures\n",
                "* Merging different data sources with `pd.merge` and `join`\n",
                "* Grouping similar data using `groupby`\n",
                "* Transforming data with `pivot_table`\n",
                "\n",
                "But with the features shown, you are on a good way to become a Software Development Analyst that can leverage Data Science to fix problems in software systems!\n",
                "\n",
                "If you want to dive deeper into this topic, take a look at my [other blog posts on that topic](http://www.feststelltaste.de/category/software-analytics/). I'm also [offering training for companies](http://markusharrer.de/) who want to fix their problems using data analysis in software development.\n",
                "\n",
                "I'm looking forward to your comments and feedback!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}